{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte I - Fundamentos\n",
    "\n",
    "* Recuperação da informação (RI)\n",
    "* Arquitetura de um sistema de recuperação da informação\n",
    "* Modelos de RI\n",
    "    * Modelo booleano\n",
    "    * Modelo vetorial\n",
    "    * Modelo probabilístico\n",
    "* Ponderação\n",
    "    * TF-IDF\n",
    "    * Normalização pelo tamanho dos documentos\n",
    "* Modelo probabilístico\n",
    "    * BM25\n",
    "* Introdução à avaliação da recuperação\n",
    "* Tópico especial: stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conceitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os documentos abaixo serão usados para ilustrar os conceitos. Vamos considerar que cada elemento da lista é um documento da nossa base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=[\"the house had a tiny little mouse\",\n",
    "      \"the cat saw the mouse\",\n",
    "      \"the mouse ran away from the house\",\n",
    "      \"the cat finally ate the mouse\",\n",
    "      \"the end of the mouse story\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words\n",
    "\n",
    "O modelo de bag of words (saco de palavras) é a representação mais comum utilizada em sistemas de recuperação da informação. Consiste basicamente do conjunto de termos únicos de todos os documentos da coleção. É este conjunto que comporá a estrutura de dados utilizada para recuperação - o índice invertido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Quebra documentos nos espaços (tokeniza)\n",
    "docs_in_tokens = [e.split(' ') for e in docs]\n",
    "\n",
    "#Transforma os tokens em um bag of words\n",
    "bag_of_words = set([item for elem in docs_in_tokens for item in elem])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A bag of words dos nossos documentos de exemplo é a listada abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'ate',\n",
       " 'away',\n",
       " 'cat',\n",
       " 'end',\n",
       " 'finally',\n",
       " 'from',\n",
       " 'had',\n",
       " 'house',\n",
       " 'little',\n",
       " 'mouse',\n",
       " 'of',\n",
       " 'ran',\n",
       " 'saw',\n",
       " 'story',\n",
       " 'the',\n",
       " 'tiny'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_of_words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency - TF\n",
    "\n",
    "Reflete o quão frequente um termo ocorre em um documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ate</th>\n",
       "      <th>away</th>\n",
       "      <th>cat</th>\n",
       "      <th>end</th>\n",
       "      <th>finally</th>\n",
       "      <th>from</th>\n",
       "      <th>had</th>\n",
       "      <th>house</th>\n",
       "      <th>little</th>\n",
       "      <th>mouse</th>\n",
       "      <th>of</th>\n",
       "      <th>ran</th>\n",
       "      <th>saw</th>\n",
       "      <th>story</th>\n",
       "      <th>the</th>\n",
       "      <th>tiny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ate  away  cat  end  finally  from  had  house  little  mouse  of  ran  \\\n",
       "0    0     0    0    0        0     0    1      1       1      1   0    0   \n",
       "1    0     0    1    0        0     0    0      0       0      1   0    0   \n",
       "2    0     1    0    0        0     1    0      1       0      1   0    1   \n",
       "3    1     0    1    0        1     0    0      0       0      1   0    0   \n",
       "4    0     0    0    1        0     0    0      0       0      1   1    0   \n",
       "\n",
       "   saw  story  the  tiny  \n",
       "0    0      0    1     1  \n",
       "1    1      0    2     0  \n",
       "2    0      0    2     0  \n",
       "3    0      0    2     0  \n",
       "4    0      1    2     0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "cv = CountVectorizer(stop_words=None)\n",
    "cv = cv.fit(docs)\n",
    "\n",
    "word_count_vector = cv.transform(docs)\n",
    "\n",
    "tf_df = pd.DataFrame(word_count_vector.toarray(),columns=cv.get_feature_names(), index=None)\n",
    "tf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverse Document Frequency - IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>the</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cat</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>1.693147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ate</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>away</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>end</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>from</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>had</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>of</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ran</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>saw</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tiny</th>\n",
       "      <td>2.098612</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         idf_weights\n",
       "mouse       1.000000\n",
       "the         1.000000\n",
       "cat         1.693147\n",
       "house       1.693147\n",
       "ate         2.098612\n",
       "away        2.098612\n",
       "end         2.098612\n",
       "finally     2.098612\n",
       "from        2.098612\n",
       "had         2.098612\n",
       "little      2.098612\n",
       "of          2.098612\n",
       "ran         2.098612\n",
       "saw         2.098612\n",
       "story       2.098612\n",
       "tiny        2.098612"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer=TfidfTransformer()\n",
    "tfidf_transformer.fit(word_count_vector)\n",
    "\n",
    "idf_df = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(),columns=[\"idf_weights\"])\n",
    " \n",
    "# sort ascending\n",
    "idf_df.sort_values(by=['idf_weights'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerando uma lista de stop words\n",
    "\n",
    "Uma abordagem para se gerar uma lista de stopwords a ser utilizada no sistema de RI é analisar a frequência das palavras no corpus. Em relação ao uso de uma lista de stopwords fixa, esta abordagem traz a vantagem de estar alinhada ao contexto da busca, uma vez que a utilidade de uma palavra está relacionado ao domínio em que ela aparece.\n",
    "\n",
    "Além disso, o padrão de uso das palavras muda com o tempo. Assim, é interessante manter a lista de stopwords atualizada conforme tendências de uso da linguagem caso uma lista esteja sendo usada.\n",
    "\n",
    "Há diferentes abordagens para se gerar lista de stopwords, por exemplo pela lei de Zipf ou pela divergência de Kullback-Leibler (entropia relativa). \n",
    "\n",
    "Aqui vamos utilizar a métrica IDF (inverse document frequency) para se ter uma ideia dos termos mais comuns do nosso corpus - os atos normativos da Presidência do TCU. \n",
    "\n",
    "No paper abaixo, há a exploração de diferentes técnicas para geração de uma lista de stop words:\n",
    "\n",
    "Automatically Building a Stopword List for an Information Retrieval System - \n",
    "http://terrierteam.dcs.gla.ac.uk/publications/rtlo_DIRpaper.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATIVE_DOCS_FOLDER = 'Dados/atos-original' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obter dados\n",
    "\n",
    "Lê todos os atos normativos para uma lista de documentos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "\n",
    "def find_files(folder, remove_empty = False):\n",
    "    \"\"\"\n",
    "    Find all files in [folder]\n",
    "\n",
    "    folder  :   string\n",
    "                    folder to search (not recursive)\n",
    "    \"\"\"\n",
    "    files =  glob.iglob(folder + '**/*.txt', recursive=True)\n",
    "    return files\n",
    "\n",
    "def get_sentences(input_file_pointer):\n",
    "    sentences = ''\n",
    "    while True:\n",
    "        line = input_file_pointer.readline()\n",
    "        \n",
    "        if not line:\n",
    "            break\n",
    "        \n",
    "        processed_line = line.strip()\n",
    "        \n",
    "        if processed_line:\n",
    "            sentences += processed_line + \" \"\n",
    "        \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diretório deste notebook\n",
    "diretorio_notebook = os.getcwd()\n",
    "\n",
    "# Diretório onde estão armazenados os dados\n",
    "diretorio_dados = os.path.join(diretorio_notebook, os.path.pardir, RELATIVE_DOCS_FOLDER)\n",
    "\n",
    "files = find_files(diretorio_dados)\n",
    "\n",
    "documentos = []\n",
    "\n",
    "for i, fpath in enumerate(files):\n",
    "    with open(fpath, encoding=\"utf8\") as f:\n",
    "        sentences = get_sentences(f)\n",
    "        documentos.append(sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF Vectorizer\n",
    "\n",
    "Obtém uma lista com os termos ordenados pelo IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idf_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>da</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>de</th>\n",
       "      <td>1.000322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tribunal</th>\n",
       "      <td>1.001289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no</th>\n",
       "      <td>1.001611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contas</th>\n",
       "      <td>1.001934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>união</th>\n",
       "      <td>1.003225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>do</th>\n",
       "      <td>1.004841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>em</th>\n",
       "      <td>1.005488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resolve</th>\n",
       "      <td>1.008731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>art</th>\n",
       "      <td>1.009706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presidente</th>\n",
       "      <td>1.011658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1º</th>\n",
       "      <td>1.023454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2º</th>\n",
       "      <td>1.028741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vigor</th>\n",
       "      <td>1.038397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>na</th>\n",
       "      <td>1.041412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>esta</th>\n",
       "      <td>1.050176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>1.064496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>que</th>\n",
       "      <td>1.068625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nº</th>\n",
       "      <td>1.072079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uso</th>\n",
       "      <td>1.076935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sua</th>\n",
       "      <td>1.104074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>publicação</th>\n",
       "      <td>1.134176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>não</th>\n",
       "      <td>1.150508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entra</th>\n",
       "      <td>1.169398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>para</th>\n",
       "      <td>1.186322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>portaria</th>\n",
       "      <td>1.226288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tcu</th>\n",
       "      <td>1.232362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>com</th>\n",
       "      <td>1.245856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>os</th>\n",
       "      <td>1.270446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3º</th>\n",
       "      <td>1.275522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172301</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172320</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172321</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172327</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172328</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172333</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172337</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17234</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172318</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172662</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172258</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172252</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172192</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172197</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172198</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1722</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17220</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172202</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172206</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172256</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172212</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172224</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172225</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172227</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172232</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172235</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172245</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172247</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172217</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253512</th>\n",
       "      <td>8.347944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>189369 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            idf_weights\n",
       "da             1.000000\n",
       "de             1.000322\n",
       "tribunal       1.001289\n",
       "no             1.001611\n",
       "contas         1.001934\n",
       "união          1.003225\n",
       "do             1.004841\n",
       "em             1.005488\n",
       "resolve        1.008731\n",
       "art            1.009706\n",
       "presidente     1.011658\n",
       "1º             1.023454\n",
       "2º             1.028741\n",
       "vigor          1.038397\n",
       "na             1.041412\n",
       "esta           1.050176\n",
       "data           1.064496\n",
       "que            1.068625\n",
       "nº             1.072079\n",
       "uso            1.076935\n",
       "sua            1.104074\n",
       "publicação     1.134176\n",
       "não            1.150508\n",
       "entra          1.169398\n",
       "para           1.186322\n",
       "portaria       1.226288\n",
       "tcu            1.232362\n",
       "com            1.245856\n",
       "os             1.270446\n",
       "3º             1.275522\n",
       "...                 ...\n",
       "172301         8.347944\n",
       "172320         8.347944\n",
       "172321         8.347944\n",
       "172327         8.347944\n",
       "172328         8.347944\n",
       "172333         8.347944\n",
       "172337         8.347944\n",
       "17234          8.347944\n",
       "172318         8.347944\n",
       "172662         8.347944\n",
       "172258         8.347944\n",
       "172252         8.347944\n",
       "172192         8.347944\n",
       "172197         8.347944\n",
       "172198         8.347944\n",
       "1722           8.347944\n",
       "17220          8.347944\n",
       "172202         8.347944\n",
       "172206         8.347944\n",
       "172256         8.347944\n",
       "172212         8.347944\n",
       "172224         8.347944\n",
       "172225         8.347944\n",
       "172227         8.347944\n",
       "172232         8.347944\n",
       "172235         8.347944\n",
       "172245         8.347944\n",
       "172247         8.347944\n",
       "172217         8.347944\n",
       "253512         8.347944\n",
       "\n",
       "[189369 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_stop = CountVectorizer(stop_words=None)\n",
    "cv_stop = cv_stop.fit(documentos)\n",
    "\n",
    "word_count_vector_stop = cv_stop.transform(documentos)\n",
    "\n",
    "tfidf_transformer_stop=TfidfTransformer()\n",
    "tfidf_transformer_stop.fit(word_count_vector_stop)\n",
    "\n",
    "idf_df_stop = pd.DataFrame(tfidf_transformer_stop.idf_, index=cv_stop.get_feature_names(),columns=[\"idf_weights\"])\n",
    " \n",
    "# sort ascending\n",
    "idf_df_stop.sort_values(by=['idf_weights'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
