{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consultas centradas no termo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quando os campos vêm diretamente do modelo de dados de origem, os cálculos TF × IDF que resultam de pesquisas não se alinham perfeitamente às expectativas do usuário. TF × IDF pode ser uma métrica ruim quando o campo e a proporção aproximada subjacente dos recursos  não são mapeados para signals que os usuários se preocupam ao classificar. Quando você pesquisa em dezenas de campos, simplesmente porque \"é isso que está no banco de dados\", você acaba com muitas dessas anomalias de pontuação que não correspondem às expectativas do usuário.\n",
    "\n",
    "A pesquisa centrada em campo amplifica a discordância de signal. Ao calcular o score de cada campo isoladamente, a pesquisa centrada em campo é propensa a influenciar fortemente os resultados da pesquisa em uma direção ou outra. Ao executar pesquisas centradas em campo em dezenas e dezenas de campos, todos os critérios possíveis do seu banco de dados, você procura por problemas.\n",
    "\n",
    "O modelo de dados de origem mantém você preso em uma visualização bottom-up, modelo de dados de origem primeiro.\n",
    "Para fazer uma boa modelagem de signals, é necessário pensar de top-down e primeiramente no usuário. Com o que os usuários se preocupam ao classificar? Como você pode criar campos do modelo de dados de origem para calcular esses signals? Qual deve ser a frequência do documento de william shatner para refletir o senso de conscientização do termo pelo usuário?\n",
    "\n",
    "Como você verá, a pesquisa centrada em termos pode ajudar a fornecer essa perspectiva de cima para baixo na modelagem de signals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PARÂMETROS\n",
    "\n",
    "#Máquina e porta (formato host:port)\n",
    "SOLR_ADDR='localhost:8983'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas\n",
    "from datetime import datetime\n",
    "headers = {'content-type': 'application/json;charset=UTF-8'}\n",
    "\n",
    "def date_diff_in_seconds(dt2, dt1):\n",
    "    timedelta = dt2 - dt1\n",
    "    return timedelta.days * 24 * 3600 + timedelta.seconds\n",
    "\n",
    "# Some utilities for flattening the explain into something a bit more\n",
    "# readable. Pass Explain JSON, get something readable (ironically this is what Solr's default output is :-p)\n",
    "def flatten(l):\n",
    "    [item for sublist in l for item in sublist]\n",
    "\n",
    "def simplerExplain(explainJson, depth=0):\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explainJson['value'], explainJson['description'])\n",
    "    #print json.dumps(explainJson, indent=True)\n",
    "    if 'details' in explainJson:\n",
    "        for detail in explainJson['details']:\n",
    "            result += simplerExplain(detail, depth=depth+1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cast_list(cast, n):\n",
    "    i = 0\n",
    "    cast_list = []\n",
    "    for e in cast:\n",
    "        i += 1\n",
    "        cast_list.append(e['name'])\n",
    "        #if i > n:\n",
    "            #cast_list.append('...')\n",
    "            #break\n",
    "    return cast_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um índice novo no Solr e reindexa os dados\n",
    "def reindex_solr(movieDict={}, delete=True):\n",
    "    if delete:\n",
    "        resp = requests.get(\"http://\" + SOLR_ADDR + \"/solr/admin/collections?action=DELETE&name=tmdb\")\n",
    "        resp = requests.get(\"http://\" + SOLR_ADDR + \"/solr/admin/collections?action=CREATE&name=tmdb&numShards=1\")\n",
    "        print(\"solr building...\", resp.status_code)\n",
    "    \n",
    "    movies = \"\"\n",
    "    \n",
    "    for id, movie in movieDict.items():\n",
    "        movies += json.dumps(movie) + \",\"\n",
    "    \n",
    "    bulkMovies = \"[\" + movies + \"]\"\n",
    "\n",
    "    print(\"solr indexing...\")\n",
    "    resp = requests.post(\"http://\" + SOLR_ADDR + \"/solr/tmdb/update/json/docs?commit=true\", data=bulkMovies, headers=headers)\n",
    "    print(\"solr indexing done.\", resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz a pesquisa especificada no Solr e imprime os resultados \n",
    "def search_solr(usersSearch, qf='title^10 overview'):\n",
    "    url = 'http://' + SOLR_ADDR + '/solr/tmdb/select?q='+ usersSearch + '&defType=edismax&qf=' + qf + '&rows=30&wt=json&fl=title,score'\n",
    "    httpResp = requests.get(url, headers=headers) #A\n",
    "    searchHits = json.loads(httpResp.text)['response']['docs']\n",
    "    print(\"Solr results\")\n",
    "    print(\"Num\\tRelevance Score\\t\\tMovie Title\") #B\n",
    "    for idx, hit in enumerate(searchHits):\n",
    "        print (\"%s\\t%s\\t\\t%s\" % (idx + 1, hit['score'], hit['title']))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz a pesquisa especificada no Elasticsearch e imprime os resultados\n",
    "def search_elastic(usersSearch, query=None):\n",
    "    if not query:\n",
    "        query = {\n",
    "            'query': {\n",
    "                'multi_match': { \n",
    "                    'query': usersSearch, #A\n",
    "                    'fields': ['title^10', 'overview'] #B\n",
    "                }\n",
    "            },\n",
    "            'size': '30'\n",
    "        }\n",
    "    \n",
    "    url = 'http://'+ ELASTIC_ADDR +'/tmdb/_search'\n",
    "    httpResp = requests.get(url, data=json.dumps(query), headers=headers) #A\n",
    "    searchHits = json.loads(httpResp.text)['hits']\n",
    "    print(\"Elasticsearch results\")\n",
    "    lista_resultados = []\n",
    "    for idx, hit in enumerate(searchHits['hits']):\n",
    "        filme = [idx + 1, hit['_score'], hit['_source']['title'], hit['_source']['overview'], get_cast_list(hit['_source']['cast'],10), get_cast_list(hit['_source']['directors'],5)]\n",
    "        lista_resultados.append(filme)\n",
    "    \n",
    "    pd.set_option('display.max_colwidth', -1)\n",
    "    \n",
    "    df = pd.DataFrame(lista_resultados,columns=['Num', 'Relevance Score', 'Movie Title', 'Overview', 'Cast', 'Director'], index=None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elasticsearch results\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Relevance Score</th>\n",
       "      <th>Movie Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11.073451</td>\n",
       "      <td>X-Men: O Confronto Final</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.081892</td>\n",
       "      <td>Acima das Nuvens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.486658</td>\n",
       "      <td>Logan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.379991</td>\n",
       "      <td>Stardust - O Mistério da Estrela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.673704</td>\n",
       "      <td>A Estrela de Belém</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8.444677</td>\n",
       "      <td>A Espaçonave Das Loucas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.940823</td>\n",
       "      <td>Um Monstro em Paris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.925139</td>\n",
       "      <td>X-Men: Dias de um Futuro Esquecido</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7.879263</td>\n",
       "      <td>Ad Astra - Rumo às Estrelas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.545320</td>\n",
       "      <td>Jornada nas Estrelas: Generations</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.545320</td>\n",
       "      <td>Jornada nas Estrelas: O Filme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.545320</td>\n",
       "      <td>Jornada nas Estrelas: Insurreição</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.545320</td>\n",
       "      <td>Jornada nas Estrelas: Nêmesis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>7.160939</td>\n",
       "      <td>Como Cães e Gatos 2 - A Vingança de Kitty Galore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>7.080252</td>\n",
       "      <td>Bambi 2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Relevance Score                                       Movie Title\n",
       "0   11.073451        X-Men: O Confronto Final                        \n",
       "1   10.081892        Acima das Nuvens                                \n",
       "2   9.486658         Logan                                           \n",
       "3   9.379991         Stardust - O Mistério da Estrela                \n",
       "4   8.673704         A Estrela de Belém                              \n",
       "5   8.444677         A Espaçonave Das Loucas                         \n",
       "6   7.940823         Um Monstro em Paris                             \n",
       "7   7.925139         X-Men: Dias de um Futuro Esquecido              \n",
       "8   7.879263         Ad Astra - Rumo às Estrelas                     \n",
       "9   7.545320         Jornada nas Estrelas: Generations               \n",
       "10  7.545320         Jornada nas Estrelas: O Filme                   \n",
       "11  7.545320         Jornada nas Estrelas: Insurreição               \n",
       "12  7.545320         Jornada nas Estrelas: Nêmesis                   \n",
       "13  7.160939         Como Cães e Gatos 2 - A Vingança de Kitty Galore\n",
       "14  7.080252         Bambi 2                                         "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usersSearch = 'jornada nas estrelas patrick stewart'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview', 'cast.name.bigramed', 'directors.name.bigramed'],      \n",
    "            'type': 'cross_fields'\n",
    "         }\n",
    "    },\n",
    "    'size': 50,\n",
    "    'explain': True\n",
    "}\n",
    "\n",
    "df = search_elastic(usersSearch, query)\n",
    "df_resumido = df[['Relevance Score', 'Movie Title']]\n",
    "df_resumido.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain for X-Men: O Confronto Final\n",
      "11.073451, max of:\n",
      "  3.8974152, sum of:\n",
      "    3.8974152, max of:\n",
      "      3.8974152, weight(cast.name.bigramed:patrick stewart in 4265) [PerFieldSimilarity], result of:\n",
      "        3.8974152, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          5.4240685, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            32, n, number of documents containing term\n",
      "            7370, N, total number of documents with field\n",
      "          0.3266095, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            64.0, dl, length of field (approximate)\n",
      "            32.694572, avgdl, average length of field\n",
      "  11.073451, sum of:\n",
      "    5.235121, max of:\n",
      "      5.235121, weight(overview:patrick in 4265) [PerFieldSimilarity], result of:\n",
      "        5.235121, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          4.799368, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            56, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.49581534, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            34.0, dl, length of field\n",
      "            42.684986, avgdl, average length of field\n",
      "    5.8383303, max of:\n",
      "      5.8383303, weight(overview:stewart in 4265) [PerFieldSimilarity], result of:\n",
      "        5.8383303, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          5.3523684, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            32, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.49581534, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            34.0, dl, length of field\n",
      "            42.684986, avgdl, average length of field\n",
      "\n",
      "Explain for Acima das Nuvens\n",
      "10.081892, max of:\n",
      "  10.081892, sum of:\n",
      "    4.533575, max of:\n",
      "      4.533575, weight(overview:estrel in 3193) [PerFieldSimilarity], result of:\n",
      "        4.533575, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          4.373464, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            86, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.47118622, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            39.0, dl, length of field\n",
      "            42.684986, avgdl, average length of field\n",
      "    5.548317, max of:\n",
      "      5.548317, weight(overview:stewart in 3193) [PerFieldSimilarity], result of:\n",
      "        5.548317, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          5.3523684, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            32, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.47118622, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            39.0, dl, length of field\n",
      "            42.684986, avgdl, average length of field\n",
      "\n",
      "Explain for Logan\n",
      "9.486658, max of:\n",
      "  2.8665266, sum of:\n",
      "    2.8665266, max of:\n",
      "      2.8665266, weight(cast.name.bigramed:patrick stewart in 474) [PerFieldSimilarity], result of:\n",
      "        2.8665266, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          5.4240685, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            32, n, number of documents containing term\n",
      "            7370, N, total number of documents with field\n",
      "          0.24021941, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            104.0, dl, length of field (approximate)\n",
      "            32.694572, avgdl, average length of field\n",
      "  9.486658, sum of:\n",
      "    4.4849434, max of:\n",
      "      4.4849434, weight(overview:patrick in 474) [PerFieldSimilarity], result of:\n",
      "        4.4849434, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          4.799368, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            56, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.42476642, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            50.0, dl, length of field (approximate)\n",
      "            42.684986, avgdl, average length of field\n",
      "    5.001714, max of:\n",
      "      5.001714, weight(overview:stewart in 474) [PerFieldSimilarity], result of:\n",
      "        5.001714, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          5.3523684, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            32, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.42476642, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            50.0, dl, length of field (approximate)\n",
      "            42.684986, avgdl, average length of field\n",
      "\n",
      "Explain for Stardust - O Mistério da Estrela\n",
      "9.379991, max of:\n",
      "  9.379991, sum of:\n",
      "    3.1717196, max of:\n",
      "      3.1717196, weight(overview:jornad in 1801) [PerFieldSimilarity], result of:\n",
      "        3.1717196, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          3.8196454, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            150, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.377441, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            64.0, dl, length of field (approximate)\n",
      "            42.684986, avgdl, average length of field\n",
      "    6.208271, max of:\n",
      "      6.208271, weight(overview:estrel in 1801) [PerFieldSimilarity], result of:\n",
      "        6.208271, score(freq=3.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          4.373464, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            86, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.6452417, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            3.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            64.0, dl, length of field (approximate)\n",
      "            42.684986, avgdl, average length of field\n",
      "      4.021658, weight(title:estrel in 1801) [PerFieldSimilarity], result of:\n",
      "        4.021658, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          4.433127, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            87, n, number of documents containing term\n",
      "            7366, N, total number of documents with field\n",
      "          0.41235596, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            3.0, dl, length of field\n",
      "            2.3998098, avgdl, average length of field\n",
      "\n",
      "Explain for A Mulher Faz o Homem\n",
      "6.0931234, max of:\n",
      "  6.0931234, sum of:\n",
      "    6.0931234, max of:\n",
      "      6.0931234, weight(overview:stewart in 241) [PerFieldSimilarity], result of:\n",
      "        6.0931234, score(freq=1.0), computed as boost * idf * tf from:\n",
      "          2.2, boost\n",
      "          5.3523684, idf, computed as log(1 + (N - n + 0.5) / (n + 0.5)) from:\n",
      "            32, n, number of documents containing term\n",
      "            6860, N, total number of documents with field\n",
      "          0.5174535, tf, computed as freq / (freq + k1 * (1 - b + b * dl / avgdl)) from:\n",
      "            1.0, freq, occurrences of term within document\n",
      "            1.2, k1, term saturation parameter\n",
      "            0.75, b, length normalization parameter\n",
      "            30.0, dl, length of field\n",
      "            42.684986, avgdl, average length of field\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query['explain'] = True\n",
    "httpResp = requests.get('http://'+ ELASTIC_ADDR +'/tmdb/_search', data=json.dumps(query), headers=headers)\n",
    "jsonResp = json.loads(httpResp.text)\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][0]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][0]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][1]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][1]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][2]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][2]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][3]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][3]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][25]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][25]['_explanation']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_elastic(users_search, query):\n",
    "    httpResp = requests.get('http://'+ ELASTIC_ADDR +'/tmdb/_validate/query?explain',data=json.dumps(query), headers=headers)\n",
    "    print('Explicação da query no Elasticsearch:')\n",
    "    json_str= json.dumps(json.loads(httpResp.text), indent=2, ensure_ascii=False).encode('utf-8')\n",
    "    print(json_str.decode())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explicação da query no Elasticsearch:\n",
      "{\n",
      "  \"_shards\": {\n",
      "    \"total\": 1,\n",
      "    \"successful\": 1,\n",
      "    \"failed\": 0\n",
      "  },\n",
      "  \"valid\": true,\n",
      "  \"explanations\": [\n",
      "    {\n",
      "      \"index\": \"tmdb\",\n",
      "      \"valid\": true,\n",
      "      \"explanation\": \"((blended(terms:[directors.name.bigramed:jornad _, cast.name.bigramed:jornad _]) blended(terms:[directors.name.bigramed:_ estrel, cast.name.bigramed:_ estrel]) blended(terms:[directors.name.bigramed:estrel patrick, cast.name.bigramed:estrel patrick]) blended(terms:[directors.name.bigramed:patrick stewart, cast.name.bigramed:patrick stewart])) | (blended(terms:[overview:jornad, title:jornad]) blended(terms:[overview:estrel, title:estrel]) blended(terms:[overview:patrick, title:patrick]) blended(terms:[overview:stewart, title:stewart])))\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': usersSearch,  #User's query\n",
    "            'fields': ['title', 'overview', 'cast.name.bigramed', 'directors.name.bigramed'],      \n",
    "            'type': 'cross_fields'\n",
    "         }\n",
    "    },\n",
    "}\n",
    "\n",
    "explain_elastic(usersSearch,query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
