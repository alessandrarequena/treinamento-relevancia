{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte II - Indexação dos dados e entendimento do cálculo de relevância\n",
    "\n",
    "Neste notebook iremos:\n",
    "* Criar um índice no Solr e Elasticsearch\n",
    "* Indexar os dados de filmes do TMDB (https://www.themoviedb.org/) \n",
    "* Realizar uma pesquisa e entender o cálculo de relevância (chamado de explain no Lucene)\n",
    "* Ajustar o índice para melhorar o cálculo de relevância\n",
    "\n",
    "### Pré-requisitos:\n",
    "\n",
    "Antes de executar este notebook, as engines de busca devem estar rodando:\n",
    "\n",
    "* Para Solr: <b>solr start -e cloud</b>\n",
    "* Para Elasticsearch: <b>elasticsearch</b>\n",
    "\n",
    "Este notebook foi testado com Solr 8.2.0 e Elasticsearch 7.6.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inicialização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from datetime import datetime\n",
    "headers = {'content-type': 'application/json;charset=UTF-8'}\n",
    "\n",
    "def date_diff_in_seconds(dt2, dt1):\n",
    "    timedelta = dt2 - dt1\n",
    "    return timedelta.days * 24 * 3600 + timedelta.seconds\n",
    "\n",
    "# Some utilities for flattening the explain into something a bit more\n",
    "# readable. Pass Explain JSON, get something readable (ironically this is what Solr's default output is :-p)\n",
    "def flatten(l):\n",
    "    [item for sublist in l for item in sublist]\n",
    "\n",
    "def simplerExplain(explainJson, depth=0):\n",
    "    result = \" \" * (depth * 2) + \"%s, %s\\n\" % (explainJson['value'], explainJson['description'])\n",
    "    #print json.dumps(explainJson, indent=True)\n",
    "    if 'details' in explainJson:\n",
    "        for detail in explainJson['details']:\n",
    "            result += simplerExplain(detail, depth=depth+1)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Criação do índice de filmes TMDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar índice e indexar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extrai os dados do json tmdb.json\n",
    "def extract():\n",
    "    f = open('data/tmdb-BR.json', encoding='UTF-8')\n",
    "    if f:\n",
    "         return json.loads(f.read());        \n",
    "    return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um índice novo no Solr e reindexa os dados\n",
    "def reindex_solr(movieDict={}, delete=True):\n",
    "    if delete:\n",
    "        resp = requests.get(\"http://localhost:8983/solr/admin/collections?action=DELETE&name=tmdb\")\n",
    "        resp = requests.get(\"http://localhost:8983/solr/admin/collections?action=CREATE&name=tmdb&numShards=1\")\n",
    "        print(\"solr building...\", resp.status_code)\n",
    "    \n",
    "    movies = \"\"\n",
    "    \n",
    "    for id, movie in movieDict.items():\n",
    "        movies += json.dumps(movie) + \",\"\n",
    "    \n",
    "    bulkMovies = \"[\" + movies + \"]\"\n",
    "\n",
    "    print(\"solr indexing...\")\n",
    "    resp = requests.post(\"http://localhost:8983/solr/tmdb/update/json/docs?commit=true\", data=bulkMovies, headers=headers)\n",
    "    print(\"solr indexing done.\", resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria um índice novo no Elastic e reindexa os dados\n",
    "def reindex_elastic(analysisSettings={}, mappingSettings={}, movieDict={}):\n",
    "    settings = { #A\n",
    "        \"settings\": {\n",
    "            \"number_of_shards\": 1, #B\n",
    "            \"index\": {\n",
    "                \"analysis\" : analysisSettings, #C\n",
    "    }}}\n",
    "\n",
    "    if mappingSettings:\n",
    "        settings['mappings'] = mappingSettings #C\n",
    "\n",
    "    resp = requests.delete(\"http://localhost:9200/tmdb\") #D\n",
    "    resp = requests.put(\"http://localhost:9200/tmdb\", \n",
    "                        data=json.dumps(settings), headers=headers)\n",
    "\n",
    "    print(\"elastic building...\", resp.status_code)\n",
    "    \n",
    "    if resp.status_code != 200:\n",
    "        print(resp.text)\n",
    "    \n",
    "    bulkMovies = \"\"\n",
    "    \n",
    "    for id, movie in movieDict.items(): \n",
    "        addCmd = {\"index\": {\"_index\": \"tmdb\", #E\n",
    "                            #\"_type\": \"movie\",\n",
    "                            \"_id\": movie['id']}}\n",
    "        bulkMovies += json.dumps(addCmd) + \"\\n\" + json.dumps(movie) + \"\\n\"\n",
    "\n",
    "    print(\"elastic indexing...\")\n",
    "    resp = requests.post(\"http://localhost:9200/_bulk\", data=bulkMovies, headers=headers)\n",
    "    print(\"elastic indexing done.\", resp.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'tmdb-BR.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-331-0ad981a7437d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmovieDict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Chama o método de reindexação indicado da engine com contagem de tempo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine_method\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-328-3cb5f60af27e>\u001b[0m in \u001b[0;36mextract\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#Extrai os dados do json tmdb.json\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mextract\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tmdb-BR.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'UTF-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m          \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'tmdb-BR.json'"
     ]
    }
   ],
   "source": [
    "movieDict = extract()\n",
    "\n",
    "#Chama o método de reindexação indicado da engine com contagem de tempo\n",
    "def reindex(engine, engine_method):\n",
    "    start = datetime.now()\n",
    "     \n",
    "    engine_method(movieDict=movieDict)\n",
    "    \n",
    "    end = datetime.now()\n",
    "    delta = date_diff_in_seconds(end, start)\n",
    "    print('%s engine done! (took %d seconds)\\n' % (engine, delta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As chamadas abaixo recriarão um índice novo no Solr e no Elastic indexandos todos os dados com detecção automática de schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex('Elastic', reindex_elastic)\n",
    "reindex('Solr', reindex_solr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ver o índice criado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_solr():\n",
    "    resp = requests.get(\"http://localhost:8983/solr/tmdb/schema\")\n",
    "    json_schema = json.loads(resp.text)['schema']\n",
    "    \n",
    "    print('Fields:')\n",
    "    fields = json_schema['fields']\n",
    "    print (json.dumps(fields, indent=2, sort_keys=True))\n",
    "    \n",
    "    print('\\nField Type text_general:')\n",
    "    field_types = json_schema['fieldTypes']\n",
    "    text_general = next((item for item in field_types if item['name'] == 'text_general'), None)\n",
    "    print (json.dumps(text_general, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_elastic():\n",
    "    resp = requests.get(\"http://localhost:9200/tmdb\")\n",
    "    json_object = json.loads(resp.text)\n",
    "    print (json.dumps(json_object, indent=2, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresenta os detalhes do índice criado no Elasticsearch. <b>Observem os nomes dos campos e os tipos.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Elastic results:')\n",
    "print_elastic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apresenta os detalhes do índice criado no Solr. <b>Observem os nomes dos campos e os tipos.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Solr results:')\n",
    "print_solr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Pesquisa básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com o índice criado no modo default, vamos realizar uma pesquisa por um filme. Queremos encontrar o filme que é sobre basquete com alienígenas, pois não lembramos o nome do filme. :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_search = 'Basquete com alienígenas'\n",
    "from IPython.display import Image\n",
    "Image(filename='img/space_jam.jpg') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz a pesquisa especificada no Solr e imprime os resultados \n",
    "def search_solr(usersSearch, qf='title^10 overview'):\n",
    "    url = 'http://localhost:8983/solr/tmdb/select?q='+ usersSearch + '&defType=edismax&qf=' + qf + '&rows=30&wt=json&fl=title,score'\n",
    "    httpResp = requests.get(url, headers=headers) #A\n",
    "    searchHits = json.loads(httpResp.text)['response']['docs']\n",
    "    print(\"Solr results\")\n",
    "    print(\"Num\\tRelevance Score\\t\\tMovie Title\") #B\n",
    "    for idx, hit in enumerate(searchHits):\n",
    "        print (\"%s\\t%s\\t\\t%s\" % (idx + 1, hit['score'], hit['title']))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Faz a pesquisa especificada no Elasticsearch e imprime os resultados\n",
    "def search_elastic(usersSearch, query=None):\n",
    "    if not query:\n",
    "        query = {\n",
    "            'query': {\n",
    "                'multi_match': { \n",
    "                    'query': usersSearch, #A\n",
    "                    'fields': ['title^10', 'overview'] #B\n",
    "                }\n",
    "            },\n",
    "            'size': '30'\n",
    "        }\n",
    "    \n",
    "    url = 'http://localhost:9200/tmdb/_search'\n",
    "    httpResp = requests.get(url, data=json.dumps(query), headers=headers) #A\n",
    "    searchHits = json.loads(httpResp.text)['hits']\n",
    "    print(\"Elasticsearch results\")\n",
    "    print(\"Num\\tRelevance Score\\t\\tMovie Title\") #B\n",
    "    for idx, hit in enumerate(searchHits['hits']):\n",
    "            print (\"%s\\t%s\\t\\t%s\" % (idx + 1, hit['_score'], hit['_source']['title']))\n",
    "    print(\"\\n\")\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = search_elastic(users_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_solr(users_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim, o veredicto é:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "HTML('''<table>\n",
    "        <tr><td><b>Solr 0 x 0 Elasticssearch</b></td></tr>\n",
    "        <tr><td><img src=\"img/source.gif\"></td></tr>\n",
    "    </table>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## O que aconteceu? \n",
    "\n",
    "### Visualização da query lucene que a engine gerou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_solr(users_search):\n",
    "    url = 'http://localhost:8983/solr/tmdb/select?q='+ users_search + '&debugQuery=true&defType=edismax&qf=title^10 overview&rows=1&wt=json&fl=title,score'\n",
    "    httpResp = requests.get(url, headers=headers) #A\n",
    "    explain = json.loads(httpResp.text)['debug']['parsedquery']\n",
    "    print('Explicação da query no Solr:')\n",
    "    print(explain)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_elastic(users_search):\n",
    "    query = {\n",
    "       'query': {\n",
    "            'multi_match': { \n",
    "                'query': users_search,  #User's query\n",
    "                'fields': ['title^10', 'overview']\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    httpResp = requests.get('http://localhost:9200/tmdb/_validate/query?explain',data=json.dumps(query), headers=headers)\n",
    "    print('Explicação da query no Elasticsearch:')\n",
    "    json_str= json.dumps(json.loads(httpResp.text), indent=2, ensure_ascii=False).encode('utf-8')\n",
    "    print(json_str.decode())\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explain_elastic(users_search)\n",
    "explain_solr(users_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Debug da análise da query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise no Solr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"http://localhost:8983/solr/tmdb/analysis/field?analysis.fieldname=title&analysis.query=\" + \n",
    "                    users_search +\n",
    "                    \"&analysis.showmatch=true&wt=json\")\n",
    "\n",
    "json_str= json.dumps(json.loads(resp.text), indent=2, ensure_ascii=False).encode('utf-8')\n",
    "print(json_str.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análise no Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "data='{\"field\": \"title\", \"text\" : \"'+ users_search + '\"}'   \n",
    "params = data.encode()\n",
    "\n",
    "resp = requests.get('http://localhost:9200/tmdb/_analyze', data=params, headers=headers)\n",
    "\n",
    "json_str= json.dumps(json.loads(resp.text), indent=2, ensure_ascii=False).encode('utf-8')\n",
    "print(json_str.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendendo o resultado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch\n",
    "\n",
    "\"explanation\": \"((overview:basquete overview:com overview:alienígenas) | (title:basquete title:com title:alienígenas)^10.0)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='img/field_centric.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "query['explain'] = True\n",
    "httpResp = requests.get('http://localhost:9200/tmdb/_search', data=json.dumps(query), headers=headers)\n",
    "jsonResp = json.loads(httpResp.text)\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][0]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][0]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][1]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][1]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][2]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][2]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][3]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][3]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][25]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][25]['_explanation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solr\n",
    "\n",
    "+(DisjunctionMaxQuery((overview:basquete | (title:basquete)^10.0)) DisjunctionMaxQuery((overview:com | (title:com)^10.0)) DisjunctionMaxQuery((overview:alienígenas | (title:alienígenas)^10.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(filename='img/term_centric.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "url = 'http://localhost:8983/solr/tmdb/select?q='+ users_search + '&debug=True&defType=edismax&qf=title^10 overview&rows=30&wt=json&fl=id,title,score'\n",
    "httpResp = requests.get(url, headers=headers)\n",
    "docs = json.loads(httpResp.text)['response']['docs']\n",
    "debug = json.loads(httpResp.text)['debug']['explain']\n",
    "print(\"Explain for %s\" % docs[0]['title'])\n",
    "print(debug[docs[0]['id']])\n",
    "print(\"Explain for %s\" % docs[1]['title'])\n",
    "print(debug[docs[1]['id']])\n",
    "print(\"Explain for %s\" % docs[2]['title'])\n",
    "print(debug[docs[2]['id']])\n",
    "print(\"Explain for %s\" % docs[3]['title'])\n",
    "print(debug[docs[3]['id']])\n",
    "print(\"Explain for %s\" % docs[25]['title'])\n",
    "print(debug[docs[25]['id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Melhorando os resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos modificar a análise para melhorar os resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticsearch\n",
    "\n",
    "Vamos alterar o analisador para o analyser <b>portuguese</b>.<p>\n",
    "(https://www.elastic.co/guide/en/elasticsearch/reference/current/analysis-lang-analyzer.html#portuguese-analyzer)\n",
    "\n",
    "Este analisador vem com o elasticsearch e o pipeline dele é:\n",
    "* \"lowercase\"\n",
    "* \"portuguese_stop\"\n",
    "* \"portuguese_keywords\"\n",
    "* \"portuguese_stemmer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mappingSettings = {\n",
    "       'properties': {\n",
    "               'title': { #A\n",
    "                   'type': 'text',\n",
    "                   'analyzer': 'portuguese'\n",
    "               },\n",
    "                'overview': {\n",
    "                   'type': 'text',\n",
    "                   'analyzer': 'portuguese'\n",
    "               }\n",
    "        }\n",
    "}\n",
    "reindex_elastic(mappingSettings=mappingSettings, movieDict=movieDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando o resultado da análise após a alteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.parse\n",
    "\n",
    "data='{\"field\": \"title\", \"text\" : \"'+ users_search + '\", \"explain\" : true}'   \n",
    "params = data.encode()\n",
    "\n",
    "resp = requests.get('http://localhost:9200/tmdb/_analyze', data=params, headers=headers)\n",
    "\n",
    "json_str= json.dumps(json.loads(resp.text), indent=2, ensure_ascii=False).encode('utf-8')\n",
    "print(json_str.decode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos repetir a pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users_search)\n",
    "query = search_elastic(users_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora ver a explicação do cálculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query['explain'] = True\n",
    "httpResp = requests.get('http://localhost:9200/tmdb/_search', data=json.dumps(query), headers=headers)\n",
    "jsonResp = json.loads(httpResp.text)\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][0]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][0]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][1]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][1]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][2]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][2]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][3]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][3]['_explanation']))\n",
    "print(\"Explain for %s\" % jsonResp['hits']['hits'][25]['_source']['title'])\n",
    "print(simplerExplain(jsonResp['hits']['hits'][25]['_explanation']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solr\n",
    "\n",
    "Vamos alterar o analisador para o analyser <b>text_pt</b>.<p>\n",
    "\n",
    "<b>Não vamos confundir o text_pt default do Solr com o text_pt utilizado na busca!</b>\n",
    "\n",
    "O text_pt default do Solr tem o seguinte pipeline:\n",
    " \n",
    "* tokenizer class=\"solr.StandardTokenizerFactory\"\n",
    "* filter class=\"solr.LowerCaseFilterFactory\"\n",
    "* filter class=\"solr.StopFilterFactory\" format=\"snowball\" words=\"lang/stopwords_pt.txt\" ignoreCase=\"true\"\n",
    "* filter class=\"solr.PortugueseLightStemFilterFactory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:8983/solr/tmdb/schema'\n",
    "data = '{\"replace-field\":{\"name\":\"title\",\"type\":\"text_pt\",\"stored\":true }}'\n",
    "httpResp = requests.post(url, data=data,headers=headers)\n",
    "print(httpResp.text)\n",
    "data = '{\"replace-field\":{\"name\":\"overview\",\"type\":\"text_pt\",\"stored\":true }}'\n",
    "httpResp = requests.post(url, data=data,headers=headers)\n",
    "print(httpResp.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reindex_solr(movieDict=movieDict, delete=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verificando o resultado da análise após a alteração"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = requests.get(\"http://localhost:8983/solr/tmdb/analysis/field?analysis.fieldname=title&analysis.query=\" + \n",
    "                    users_search +\n",
    "                    \"&analysis.showmatch=true&wt=json\")\n",
    "\n",
    "json_str= json.dumps(json.loads(resp.text), indent=2, ensure_ascii=False).encode('utf-8')\n",
    "print(json_str.decode())\n",
    "explain_solr(users_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos repetir a pesquisa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(users_search)\n",
    "search_solr(users_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://localhost:8983/solr/tmdb/select?q='+ users_search + '&debug=True&defType=edismax&qf=title^10 overview&rows=30&wt=json&fl=id,title,score'\n",
    "httpResp = requests.get(url, headers=headers)\n",
    "docs = json.loads(httpResp.text)['response']['docs']\n",
    "debug = json.loads(httpResp.text)['debug']['explain']\n",
    "print(\"Explain for %s\" % docs[0]['title'])\n",
    "print(debug[docs[0]['id']])\n",
    "print(\"Explain for %s\" % docs[1]['title'])\n",
    "print(debug[docs[1]['id']])\n",
    "print(\"Explain for %s\" % docs[2]['title'])\n",
    "print(debug[docs[2]['id']])\n",
    "print(\"Explain for %s\" % docs[3]['title'])\n",
    "print(debug[docs[3]['id']])\n",
    "print(\"Explain for %s\" % docs[25]['title'])\n",
    "print(debug[docs[25]['id']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.\tMelhorando os resultados 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora vamos refletir sobre as expectativas do usuário em relação à consulta:\n",
    "\n",
    "* O usuário espera que se o seu termo de busca seja encontrado no título isso significa que o documento é mais importante?\n",
    "* Outros questionamentos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elasticsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_search = 'Basquete com alienígenas'\n",
    "query = {\n",
    "    'query': {\n",
    "        'multi_match': { \n",
    "            'query': users_search,\n",
    "            'fields': ['title', 'overview'],\n",
    "        }\n",
    "    },\n",
    "    'explain': True\n",
    "}\n",
    "\n",
    "query = search_elastic(users_search, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_solr(users_search,qf='title overview')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
